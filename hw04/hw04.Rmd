---
title: "DATA621 - Insurance"
author: "Daniel Hong, Mauricio Alarcon, Maxwell Wagner"
date: "October 10, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


* * * 


## 1. DATA EXPLORATION (25 Points)
Describe the size and the variables in the moneyball training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you aren't doing your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median

```{r}
require("plyr")
require("knitr")
require("psych")
# Let's load the data

training <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw04/insurance_training_data.csv'))
metadata <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw04/insurance-metadata.csv'))
evaluation <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw04/insurance-evaluation-data.csv'))

kable(metadata)
columns <- colnames(training)
target <- "TARGET_FLAG"
inputs <- columns[!columns %in% c(target,"INDEX")]


summary <- describe(training[,c(target,inputs)])[,c("n","mean","sd","median","min","max")]
summary$completeness <- summary$n/nrow(training)
summary$cv <- 100*summary$sd/summary$mean

kable(summary)

head(training)
summary(training)
```

## 2. DATA PREPARATION (25 Points)

Based on the dataset description we need to:

 * Convert INCOME to numeric, replace 0 for NA
 * Convert PARENT1 to flag (1/0)
 * Convert HOME_VAL to NON_HOMEOWNER flag
 * Convert MSTATUS to Flag IS_SINGLE (1/0)
 * Convert SEX to Flag (IS_MALE)
 * Breakout EDUCATION into ED_HS, ED_BACHELORS,ED_MASTERS, ED_PHD
 * Breakout JOB into JOB_BLUE_COLLAR, JOB_CLERICAL, JOB_PROFESSIONAL, JOB_MANAGERIAL, JOB_LAWYER, JOB_STUDENT,JOB_DOCTOR, JOB_HOME_MAKER
 * Convert CAR_USE to flat(1/0 IS_COMMERCIAL)
 * Convert BLUEBOOK to numeric
 * Breakout CAR_TYPE into: CAR_PANEL_TRUCK,CAR_PICKUP,CAR_SPORTS_CAR,CAR_VAN,CAR_SUV
 * Convert RED_CAR to flag (1/0)
 * Convert OLDCLAIM to numeric   
 * Convert REVOKED to flag (1/0)
 * Convert URBANICITY to flag (1/0 IS_URBAN)
 * Cap numerical values to their 5/95 percentiles
 * Fill missing values with mean for: AGE, YOJ, CAR_AGE
 
```{r}

parseStringValue <- function(v, zeroToNa){
  tmpVal <- as.numeric(gsub("[\\$,]","", v))
  if (!is.na(tmpVal) && tmpVal == 0 && zeroToNa) { NA } else {tmpVal}
}

transform <- function(d){
  outputCols<- c("TARGET_FLAG","TARGET_AMT","AGE", "YOJ", "CAR_AGE","KIDSDRIV","HOMEKIDS","TRAVTIME","TIF","CLM_FREQ","MVR_PTS","CAR_AGE")
  

  #* Convert INCOME to numeric, replace 0 for NA
  d['INCOME'] <- parseStringValue(d['INCOME'],TRUE)
  outputCols <- c(outputCols,'INCOME')
 
  #* Convert PARENT1 to flag (1/0)
  d['PARENT1'] <- if (d['PARENT1']=="Yes") {1} else {0}

  #* Convert HOME_VAL to NON_HOMEOWNER flag
  d['NON_HOMEOWNER'] <- if (is.na(parseStringValue(d['HOME_VAL'],TRUE))) {1} else {0}
  outputCols <- c(outputCols,'NON_HOMEOWNER')
  
  #* Convert MSTATUS to Flag  IS_SINGLE (1/0
  #levels(training$MSTATUS)
  d['IS_SINGLE'] <- if (d['MSTATUS']=="z_No") {1} else {0}
  outputCols <- c(outputCols,'IS_SINGLE')

  #* Convert SEX to Flag (IS_MALE)
  d['IS_MALE'] <- if (d['SEX']=="M") {1} else {0}
  outputCols <- c(outputCols,'IS_MALE')
  
  #* Breakout EDUCATION into ED_HS, ED_BACHELORS,ED_MASTERS, ED_PHD
  d['ED_HS'] <- if (d['EDUCATION']=="z_High School") {1} else {0}
  d['ED_BACHELORS'] <- if (d['EDUCATION']=="Bachelors") {1} else {0}
  d['ED_MASTERS'] <- if (d['EDUCATION']=="Masters") {1} else {0}
  d['ED_PHD'] <- if (d['EDUCATION']=="PhD") {1} else {0}
  outputCols <- c(outputCols,'ED_HS','ED_BACHELORS','ED_MASTERS','ED_PHD')

  #* Breakout JOB into JOB_BLUE_COLLAR, JOB_CLERICAL, JOB_PROFESSIONAL, JOB_MANAGERIAL, JOB_LAWYER, JOB_STUDENT, JOB_DOCTOR, JOB_HOME_MAKER
  d['JOB_BLUE_COLLAR'] <- if (d['JOB']=="z_Blue Collar") {1} else {0}
  d['JOB_CLERICAL'] <- if (d['JOB']=="Clerical") {1} else {0}
  d['JOB_PROFESSIONAL'] <- if (d['JOB']=="Professional") {1} else {0}
  d['JOB_MANAGERIAL'] <- if (d['JOB']=="Manager") {1} else {0}
  d['JOB_LAWYER'] <- if (d['JOB']=="Lawyer") {1} else {0}
  d['JOB_STUDENT'] <- if (d['JOB']=="Student") {1} else {0}
  d['JOB_DOCTOR'] <- if (d['JOB']=="Doctor") {1} else {0}
  d['JOB_HOME_MAKER'] <- if (d['JOB']=="Home Maker") {1} else {0}
  outputCols <- c(outputCols,'JOB_BLUE_COLLAR', 'JOB_CLERICAL', 'JOB_PROFESSIONAL', 'JOB_MANAGERIAL', 'JOB_LAWYER', 'JOB_STUDENT', 'JOB_DOCTOR', 'JOB_HOME_MAKER')

  #* Convert CAR_USE to flat(1/0 IS_COMMERCIAL)
  #levels(training$CAR_USE)
  d['IS_COMMERCIAL'] <- if (d['CAR_USE']=="Commercial") {1} else {0}
  outputCols <- c(outputCols,'IS_COMMERCIAL')
  
  
  #* Convert BLUEBOOK to numeric
  d['BLUEBOOK'] <- parseStringValue(d['BLUEBOOK'],FALSE)
  outputCols <- c(outputCols,'BLUEBOOK')

  #* Breakout CAR_TYPE into: CAR_PANEL_TRUCK,CAR_PICKUP,CAR_SPORTS_CAR,CAR_VAN,CAR_SUV
  #levels(training$CAR_TYPE)
  d['CAR_PANEL_TRUCK'] <- if (d['CAR_TYPE']=="Panel Truck") {1} else {0}
  d['CAR_PICKUP'] <- if (d['CAR_TYPE']=="Pickup") {1} else {0}
  d['CAR_SPORTS_CAR'] <- if (d['CAR_TYPE']=="Sports Car") {1} else {0}
  d['CAR_VAN'] <- if (d['CAR_TYPE']=="Van") {1} else {0}
  d['CAR_SUV'] <- if (d['CAR_TYPE']=="z_SUV") {1} else {0}
  outputCols <- c(outputCols,'CAR_PANEL_TRUCK','CAR_PICKUP','CAR_SPORTS_CAR','CAR_VAN','CAR_SUV')

  #* Convert RED_CAR to flag (1/0)
  #levels(training$RED_CAR)
  d['RED_CAR'] <- if (d['RED_CAR']=="yes") {1} else {0}
  outputCols <- c(outputCols,'RED_CAR')
  
  #* Convert OLDCLAIM to numeric
  #levels(training$OLDCLAIM)
  d['OLDCLAIM'] <- parseStringValue(d['OLDCLAIM'],TRUE)
  outputCols <- c(outputCols,'OLDCLAIM')
  
  #* Convert REVOKED to flag (1/0)
  #levels(training$REVOKED)
  d['REVOKED'] <- if (d['REVOKED']=="Yes") {1} else {0}
  outputCols <- c(outputCols,'REVOKED')
  
  #* Convert URBANICITY to flag (1/0 IS_URBAN)
  #levels(training$URBANICITY)
  d['IS_URBAN'] <- if (d['URBANICITY']=="Highly Urban/ Urban") {1} else {0}
  outputCols <- c(outputCols,'IS_URBAN')
  
   
  d[outputCols]

}
training_trans<-data.frame(t(rbind(apply(training,1,transform))))
evaluation_trans<-data.frame(t(rbind(apply(evaluation,1,transform))))





columns <- colnames(training_trans)
target <- c("TARGET_FLAG","TARGET_AMT")
inputs <- columns[!columns %in% c(target,"INDEX")]


summary <- describe(training_trans[,c(target,inputs)])[,c("n","mean","sd","median","min","max")]
summary$completeness <- summary$n/nrow(training_trans)
summary$cv <- 100*summary$sd/summary$mean

kable(summary)

head(training_trans)
summary(training_trans)


  #* Cap numerical values to their 5/95 percentiles
  #* Fill missing values with mean for: AGE, YOJ, CAR_AGE

```

# <----- I'M DOWN TO HERE.... MA


```{r}

transformed <- training

cap <- function(x){
    quantiles <- c( qnorm(0.05,mean(x),sd(x)), qnorm(0.95,mean(x),sd(x)) )
    x[ x < quantiles[1] ] <- max(0,quantiles[1])
    x[ x > quantiles[2] ] <- quantiles[2]
    x
}

#transformed$black <- log(transformed$black)
transformed<-data.frame(apply( transformed[,inputs],2, cap),target=transformed$target)


```

### Dealing with Missing data

``` 
training<-training[complete.cases(training),]

```

b. Bar Chart or Box Plot of the data

### How are the input values distributed?, do we need to do something about them?

Here's the distribution of the values for each of the variables

Let's get a view of the normalized values:

```{r}
require("reshape2")
require("ggplot2")
# Let's melt the DF so that we can plot it more easily
training_normalized <- data.frame(scale(training[,inputs]),target=training[,target])


ggplot(melt(training_normalized, measure.vars = inputs),
       aes(x=variable,y=value)
       )+
    geom_boxplot(aes(fill = factor(target)))+
  guides(fill=guide_legend(title="Was Car in a crash")) +
   theme(legend.position="bottom")+
    coord_flip()+
  labs(title="Boxplot of Target ~ Predictors", y="Normalized Values", x="Predictor")

```

possible correlations

```{r}


summary_positive <- describe(training_normalized[training_normalized$target==1,c(target,inputs)])[,c("mean","n")]
summary_negative <- describe(training_normalized[training_normalized$target==0,c(target,inputs)])[,c("mean","n")]
summary_by_target <- merge(summary_positive,summary_negative,by="row.names")
colnames(summary_by_target) <- c("Variable","In car crash - Avg","In car crash - n","NOT In car crash - Avg", "NOT In car crash - n")
summary_by_target$delta <- abs(summary_by_target[,"In car crash - Avg"]-summary_by_target[,"NOT In car crash - Avg"])

kable(merge(metadata,summary_by_target)[order(-summary_by_target$delta),])
```



## TRAINIG DATASETS

split the dataset into training and testing

```{r}


## 75% of the sample size
smp_size <- floor(0.75 * nrow(transformed))

## set the seed to make your partition reproductible
set.seed(123)
train_ind <- c(sample(seq_len(nrow(transformed[transformed$target==1,])), size = smp_size/2),sample(seq_len(nrow(transformed[transformed$target==0,])), size = smp_size/2))

train <- transformed[train_ind, ]
test <- transformed[-train_ind, ]
```



```{r}

model <- glm(I(target)~.,data=train,family = binomial)

summary(model)

predicted <- predict(model,test,type='response')
require("pROC")
d_roc <- roc(ifelse(test$target>0.5,1,0),predicted)
plot(d_roc, main = "ROC with pROC")
#ci(d_roc)

require("caret")
table(ifelse(test$target>0.5,1,0),ifelse(predicted>0.5,1,0))

```


regression after transformations




## 3. BUILD MODELS (25 Points)

Using the training data, build at least three different binary logistic regression models, using different variables (or the same variables with different transformations). You may select the variables manually, use an approach such as Forward or Stepwise, use a different approach, or use a combination of techniques. Describe the techniques you used. If you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done.

Be sure to explain how you can make inferences from the model, as well as discuss other relevant model output. Discuss the coefficients in the models, do they make sense? Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.

```{r}
valid_data <- transformed
predictors <- inputs[!inputs %in% c("indus","chas","lstat","rm","black","zn")]

model <- glm(I(target)~.,data=train[,c(predictors,target)],family = binomial)

summary(model)

predicted <- predict(model,test,type='response')
require("pROC")
d_roc <- roc(test$target,predicted)
plot(d_roc, main = "ROC with pROC")
#ci(d_roc)



plot(model)

require("caret")
table(test$target,ifelse(predicted>0.5,1,0))

```


```{r}

d<- data.frame(class=test$target,scored.class=ifelse(predicted>0.5,1,0))

# let's use this helper function that will return all the rates for future calculations
confusion_matrix <- function(d){
  data.frame(tp=nrow(d[d$class==1 & d$scored.class==1,]),
             tn=nrow(d[d$class==0 & d$scored.class==0,]),
             fp=nrow(d[d$class==0 & d$scored.class==1,]),
             fn=nrow(d[d$class==1 & d$scored.class==0,])
  )
}

confusion_matrix(d)
accuracy<-function(d){
  f <- confusion_matrix(d)
  (f$tp+f$tn)/(f$tp+f$fp+f$tn+f$fn)
}
accuracy(d)

classification_error_rate<-function(d){
  f <- confusion_matrix(d)
  (f$fp+f$fn)/(f$tp+f$fp+f$tn+f$fn)
}
classification_error_rate(d)

precision_c<-function(d){
  f <- confusion_matrix(d)
  (f$tp)/(f$tp+f$fp)
}
precision_c(d)

sensitivity_c<-function(d){
  f <- confusion_matrix(d)
  (f$tp)/(f$tp+f$fn)
}
sensitivity_c(d)

specificity_c<-function(d){
  f <- confusion_matrix(d)
  (f$tn)/(f$tn+f$fp)
}
specificity_c(d)


f1_score<-function(d){
  p<- precision_c(d)
  s<- sensitivity_c(d)
  2*p*s/(p+s)
}
f1_score(d)


```

## 4. SELECT MODELS (25 Points)

Decide on the criteria for selecting the best binary logistic regression model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your models. 

For the binary logistic regression model, will you use a metric such as log likelihood, AIC, ROC curve, etc.? Using the training data set, evaluate the binary logistic regression model based on (a) accuracy, (b) classification error rate, (c) precision, (d) sensitivity, (e) specificity, (f) F1 score, (g) AUC, and (h) confusion matrix. Make predictions using the evaluation data set.


# Predictions

```{r}

mean_sd <- function(x){
  c( qnorm(0.05,mean(x),sd(x)), qnorm(0.95,mean(x),sd(x)) )
}


trans_params<-data.frame(apply( transformed[,inputs],2, mean_sd))

cap <- function(col){
    quantiles <- trans_params[,col]
    x <- evaluation[,col]
    x[ x < quantiles[1] ] <- max(0,quantiles[1])
    x[ x > quantiles[2] ] <- quantiles[2]
    x
}

#transformed$black <- log(transformed$black)

evaluation_transformed <- data.frame(sapply(inputs,function(x){cap(x)}))
evaluation$predict <- predict(model,evaluation_transformed,type='response')>0.5

kable(data.frame(evaluation))
```