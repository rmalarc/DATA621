---
title: "DATA621 - Moneyball"
author: "Daniel Hong, Mauricio Alarcon, Maxwell Wagner"
date: "September 11, 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* * *

# NOTES 

## Missing Data:

* TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_PITCHING_SO and TEAM_FIELDING_DP are 90% or so complete, can we fill missing values with mean/median
* TEAM_BASERUN_CS, TEAM_BATTING_HBP are on the very incomplete side (66%, 8% respectively). Perhaps we can conver to Percent of Games Caught Stealing?, etc?
* I know nothing about baseball, can we tell the Number of Games Played? 

## Value Distribution:

* A lot of variables have a long tail. In particular, TEAM_PITCHING_H, TEAM_BATTING_SO, TEAM_PITCHING_BB have a VERY long tail, any ideas about trimming this values? (capping/ transformation)?

## Correlations

The collosal scatterplot https://github.com/rmalarc/DATA621/blob/master/hw01/Rplot01.png shows some correlations, particularly TEAM_BATTING_H + TEAM_BATTING_2B, TEAM_BATTING_3B ~ target. Any ideas?




* * * 


## 1. DATA EXPLORATION (25 Points)
Describe the size and the variables in the moneyball training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you aren't doing your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median

```{r}
require("plyr")
require("knitr")
require("psych")
# Let's load the data

training <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw01/moneyball-training-data.csv'))
metadata <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw01/moneyball-metadata.csv'))
evaluation <- read.csv(url('https://raw.githubusercontent.com/rmalarc/DATA621/master/hw01/moneyball-evaluation-data.csv'))

kable(metadata)
columns <- colnames(training)
target <- "TARGET_WINS"
inputs <- columns[!columns %in% c(target,"INDEX")]

summary <- describe(training[,c(target,inputs)])[,c("n","mean","sd","median","max","min")]
summary$completeness <- summary$n/nrow(training)
kable(summary)

```

b. Bar Chart or Box Plot of the data

### How are the input values distributed?, do we need to do something about them?

Here's the distribution of the values for each of the variables

```{r}
require("reshape2")
require("ggplot2")
# Let's melt the DF so that we can plot it more easily

ggplot(melt(training, measure.vars = c(target,inputs))
       ,aes(x=variable,y=value)
       )+
    geom_boxplot() +
    coord_flip()
```

Some of these probably need to be rescaled: TEAM_PITCHING_H, TEAM_PITCHING_SO  (what is this????)

Let's get a view of the normalized values:

```{r}
require("reshape2")
require("ggplot2")
# Let's melt the DF so that we can plot it more easily

ggplot(melt(data.frame(scale(training)), measure.vars = c(target,inputs)),
       aes(x=variable,y=value)
       )+
    geom_boxplot() +
    coord_flip()

```

the case for data transformations is a lot more self-evident now!

Let's see what it looks like with a log transformation:

```{r}
ggplot(melt(data.frame(scale(log(training))), measure.vars = c(target,inputs)),
       aes(x=variable,y=value)
       )+
    geom_boxplot() +
    coord_flip()

```

c. Is the data correlated to the target variable (or to other variables?)

```{r}
pairs(~.,data=training[,c(target,inputs)], 
   main="Scatterplot Matrix")

# LEt's see the correlation matrix

kable(cor(training[,c(target,inputs)], use="pairwise.complete.obs", method="kendall") )
```


d. Are any of the variables missing and need to be imputed "fixed"?


## 2. DATA PREPARATION (25 Points)
Describe how you have transformed the data by changing the original variables or creating new variables. If you did transform the data or create new variables, discuss why you did this. Here are some possible transformations.

a. Fix missing values (maybe with a Mean or Median value)
b. Create flags to suggest if a variable was missing
c. Transform data by putting it into buckets
d. Mathematical transforms such as log or square root (or use Box-Cox)
e. Combine variables (such as ratios or adding or multiplying) to create new variables


```{r}

# and a refression on the raw data to see what comes out of it
complete_cols <- row.names( summary[summary$completeness == 1,])
complete_cols <- c(complete_cols[complete_cols!=target])

training_transformed <- training[,c(target,complete_cols)]


# make up for missing TEAM_BATTING_SO
training[is.na(training$TEAM_BATTING_SO),]$TEAM_BATTING_SO <- median(training$TEAM_BATTING_SO, na.rm = TRUE)
training_transformed$TEAM_BATTING_SO <- training$TEAM_BATTING_SO

# make up for missing TEAM_BASERUN_SB
training[is.na(training$TEAM_BASERUN_SB),]$TEAM_BASERUN_SB <- median(training$TEAM_BASERUN_SB, na.rm = TRUE)
training_transformed$TEAM_BASERUN_SB <- training$TEAM_BASERUN_SB

# make up for missing TEAM_PITCHING_SO
training[is.na(training$TEAM_PITCHING_SO),]$TEAM_PITCHING_SO <- median(training$TEAM_PITCHING_SO, na.rm = TRUE)
training_transformed$TEAM_PITCHING_SO <- training$TEAM_PITCHING_SO

# make up for missing TEAM_FIELDING_DP
training[is.na(training$TEAM_FIELDING_DP),]$TEAM_FIELDING_DP <- median(training$TEAM_FIELDING_DP, na.rm = TRUE)
training_transformed$TEAM_FIELDING_DP <- training$TEAM_FIELDING_DP

# make up for missing TEAM_BASERUN_CS
#training[is.na(training$TEAM_BASERUN_CS),]$TEAM_BASERUN_CS  <- median(training$TEAM_BASERUN_CS, na.rm = TRUE)
#training_transformed$TEAM_BASERUN_CS <- training$TEAM_BASERUN_CS 


#training_transformed$TEAM_BATTING_1B <- (training_transformed$TEAM_BATTING_2B-training_transformed$TEAM_BATTING_3B+training_transformed$TEAM_BATTING_HR)

# validation algo
#training_transformed$INVALID <- FALSE
#training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_1B < 811 | training_transformed$TEAM_BATTING_1B>1338
#length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- FALSE
training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_2B < 110 | training_transformed$TEAM_BATTING_2B>376
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_3B < 11 | training_transformed$TEAM_BATTING_3B>153
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_HR < 3 | training_transformed$TEAM_BATTING_HR>264
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_H < 935 | training_transformed$TEAM_BATTING_H>2131
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_SO < 308 | training_transformed$TEAM_BATTING_SO>1535
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_PITCHING_SO < 308 | training_transformed$TEAM_PITCHING_SO>1535
length(training_transformed$INVALID[training_transformed$INVALID])


training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BATTING_BB < 282 | training_transformed$TEAM_BATTING_BB>835
length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_PITCHING_BB < 282 | training_transformed$TEAM_PITCHING_BB>835
length(training_transformed$INVALID[training_transformed$INVALID])

#training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BASERUN_CS < 8 | training_transformed$TEAM_BASERUN_CS>191
#length(training_transformed$INVALID[training_transformed$INVALID])

training_transformed$INVALID <- training_transformed$INVALID | training_transformed$TEAM_BASERUN_SB < 13 | training_transformed$TEAM_BASERUN_SB>638
length(training_transformed$INVALID[training_transformed$INVALID])

#training_transformed <- training_transformed[!training_transformed$INVALID,]


#training_transformed$TEAM_BATTING_1B <- training_transformed$TEAM_BATTING_1B/training_transformed$TEAM_BATTING_H

#training_transformed$TEAM_BATTING_2B <- training_transformed$TEAM_BATTING_2B/training_transformed$TEAM_BATTING_H
#training_transformed$TEAM_BATTING_3B <- training_transformed$TEAM_BATTING_3B/training_transformed$TEAM_BATTING_H
#training_transformed$TEAM_BATTING_HR <- training_transformed$TEAM_BATTING_HR/training_transformed$TEAM_BATTING_H


#training_transformed$TEAM_PITCHING_HR <- training_transformed$TEAM_PITCHING_HR/training_transformed$TEAM_PITCHING_H


library(MASS)
valid_data <- training_transformed[!training_transformed$INVALID&complete.cases(training_transformed),colnames(training_transformed)[!colnames(training_transformed) %in% c("INVALID")]]

```
# Model 0: A Mean based model

Let's try a straight up regression whatever linear regression

```{r}


model <- lm(TARGET_WINS~1,data=valid_data)
summary(model)
model0 <- model
model0_y_power <- 1
plot(model)



```


# Model 1: A Straight Up Model

Let's try a straight up regression whatever linear regression

```{r}


model <- lm(TARGET_WINS~.+0,data=valid_data)
summary(model)
model1 <- model
model1_y_power <- 1
model1_powers <- 1
plot(model)



```

# Model 2: A Power Model on Just Y

The residual curves look funky. Let's apply some power transformations to the same model:

```{r}

getBoxCoxCoef<-function(x,y){
  if (min(x)<=0){1} else {
    d<-boxcox(x~y, plotit = FALSE)
    d <- data.frame(d)
    max_x <- d[d$y == max(d$y),]$x
    if (abs(max_x)<=(1/3)) 1 else max_x
  }
}

model_data <- valid_data

d<-boxcox(TARGET_WINS+0.0001~.,data=model_data, plotit = FALSE)

d <- data.frame(d)

y_power <- d[d$y == max(d$y),]$x
y_power
model_data$TARGET_WINS <- with(model_data,TARGET_WINS^y_power)
model <- lm(TARGET_WINS~.+0,data=model_data)
summary(model)
model2 <- model
model2_y_power <- y_power
model2_powers <- y_power

plot(model)



```


# Model 3: A Power Model on Y and X

The residual curves look funky. Let's apply some power transformations to the same model:

```{r}
model_data <- valid_data[,c("TEAM_BATTING_H"
,"TEAM_BATTING_3B"
,"TEAM_BATTING_BB"
,"TEAM_FIELDING_E"
,"TEAM_BASERUN_SB"
,"TEAM_FIELDING_DP","TARGET_WINS")]
#,"TEAM_BATTING_HR"
#,"TEAM_PITCHING_HR"
#,"TEAM_PITCHING_BB"

source_cols <- colnames(model_data)

source_cols <- source_cols[source_cols!="TARGET_WINS"]

powers <- lapply(source_cols,function(x){getBoxCoxCoef(model_data[,x],model_data$TARGET_WINS^y_power)})

params <- c(unlist(powers),y_power)
kable(data.frame(variable=c(source_cols,"TARGET_WINS"),power=params))

power_transforms <- data.frame(t(apply(model_data,1,function(c) { c^params})))

#model <- lm(TARGET_WINS~.,data=power_transforms[,colnames(power_transforms)[!colnames(power_transforms) %in% c("TEAM_PITCHING_H","TEAM_BATTING_H")]])
#summary(model)
model <- lm(TARGET_WINS~.+0,power_transforms)
summary(model)
model3 <- model
model3_y_power <- y_power
model3_powers <- powers
plot(model)



```

# Models With Advanced Feature/Transformation Selection: Evaluating transformations 

Let's get fancy by trying other variables/combinations


```{r}




combinations <- t(combn(colnames(valid_data)[colnames(valid_data)!="TARGET_WINS"],2))

try_Variable <- function(x,y,label){
  y_power <- getBoxCoxCoef(y+0.00001,x)
  x_power <- getBoxCoxCoef(x+0.00001,y)
  model <- lm(I(y^y_power)~I(x^x_power)+0)
  s <- summary(model)
  res <- data.frame(try=paste0(label,"^",x_power),
                    r2=s$r.squared,
                    x_power=x_power,
                    y_power=y_power,
             coef=s$coefficients[,"Estimate"][1],
             coef_p=s$coefficients[,"Pr(>|t|)"][1],
             t_value=s$coefficients[,"t value"][1],
             min_x=min(x),
             max_x=max(x),
             f=s$fstatistic["value"],
             mse=mean(s$residuals^2),
             rse=sd(s$residuals),
             stringsAsFactors=FALSE
  )
  rownames(res) <- NULL
  res
}

evaluate_variables <- function(data,combination,target){
  try_this <- data.frame(x = data[,combination[1]]*data[,combination[2]],y=data[,target])
  res_1 <- try_Variable(try_this$x,try_this$y,paste0("(",combination[1],"*",combination[2],")"))

  try_this <- data.frame(x = data[,combination[1]]/(data[,combination[2]]+0.0000001),y=data[,target])
  res_2 <- try_Variable(try_this$x,try_this$y,paste0("(",combination[1],"/",combination[2],")"))

  total<-rbind(res_1,res_2)
  rownames(total) <- NULL
  total
}

evaluate_variable <- function(data,variable,target){
  try_this <- data.frame(x = data[,variable],y=data[,target])
  res_1 <- try_Variable(try_this$x,try_this$y,paste0("(",variable,")"))


  rownames(res_1) <- NULL
  res_1
}

evaluate_variable_log <- function(data,variable,target){
  try_this <- data.frame(x = log(data[,variable]+0.000001),y=data[,target])
  res_1 <- try_Variable(try_this$x,try_this$y,paste0("log(",variable,")"))


  rownames(res_1) <- NULL
  res_1
}

unique_cols <- c(unique(c(combinations[,1],combinations[,2])))


the_medium_tamale<-lapply(unique_cols,function(c){evaluate_variable(valid_data,c,"TARGET_WINS")})
the_medium_tamale<-do.call(rbind,the_medium_tamale)

the_log_tamale<-lapply(unique_cols,function(c){evaluate_variable_log(valid_data,c,"TARGET_WINS")})
the_log_tamale<-do.call(rbind,the_log_tamale)

the_big_tamale<-apply(combinations,1,function(c){evaluate_variables(valid_data,c,"TARGET_WINS")})
the_big_tamale<-do.call(rbind,the_big_tamale)

the_tamale <- rbind(the_medium_tamale,the_log_tamale,the_big_tamale)

kable(the_tamale[order(-the_tamale$r2),])

```

### Models Based on Calculated Measures - Model 4



```{r}
########
# select columns for model

head(the_tamale[order(-the_tamale$r2),c("try","r2","coef_p")],8)


model_data <- data.frame(TEAM_BATTING_3B_OVER_TEAM_FIELDING_E = with(valid_data,TEAM_BATTING_3B/TEAM_FIELDING_E),
TEAM_BATTING_2B_BY_TEAM_PITCHING_BB = with(valid_data,TEAM_BATTING_2B*TEAM_PITCHING_BB),
TEAM_BATTING_3B_BY_TEAM_PITCHING_HR = with(valid_data,TEAM_BATTING_3B*TEAM_PITCHING_HR),
TEAM_BATTING_2B_BY_TEAM_BATTING_BB = with(valid_data,TEAM_BATTING_2B*TEAM_BATTING_BB),
TEAM_BATTING_3B_BY_TEAM_BATTING_HR = with(valid_data,TEAM_BATTING_3B*TEAM_BATTING_HR),
TEAM_BATTING_BB_BY_TEAM_PITCHING_BB = with(valid_data,TEAM_BATTING_BB),
TEAM_PITCHING_HR_OVER_TEAM_BATTING_SO = with(valid_data,TEAM_BATTING_BB*TEAM_PITCHING_BB),
TEAM_BATTING_BB = with(valid_data,TEAM_PITCHING_HR/TEAM_BATTING_SO),
  TARGET_WINS=with(valid_data,TARGET_WINS)
)

d<-boxcox(TARGET_WINS+0.0001~.,data=model_data, plotit = TRUE)

d <- data.frame(d)

y_power <- d[d$y == max(d$y),]$x

source_cols <- colnames(model_data)

source_cols <- source_cols[source_cols!="TARGET_WINS"]

powers <- lapply(source_cols,function(x){getBoxCoxCoef(model_data[,x],model_data$TARGET_WINS^y_power)})

params <- c(unlist(powers),y_power)
kable(data.frame(variable=c(source_cols,"TARGET_WINS"),power=params))

power_transforms <- data.frame(t(apply(model_data,1,function(c) { c^params})))


#model <- lm(TARGET_WINS~.,data=power_transforms[,colnames(power_transforms)[!colnames(power_transforms) %in% c("TEAM_PITCHING_H","TEAM_BATTING_H")]])
#summary(model)
model <- lm(TARGET_WINS~.+0,power_transforms[,colnames(power_transforms)[!colnames(power_transforms) %in% c("TEAM_BATTING_3B_BY_TEAM_PITCHING_HR","TEAM_BATTING_BB_BY_TEAM_PITCHING_BB")]])
summary(model)
model4 <- model
model4_y_power <- y_power
model4_powers <- powers

plot(model)



```



# Model 5: A Straight Up Model, w/o intercept calcellation

Let's try a straight up regression whatever linear regression

```{r}


model <- lm(TARGET_WINS~.,data=valid_data)
summary(model)
model5 <- model
model5_y_power <- 1
model5_powers <- powers

plot(model)



```




## 3. BUILD MODELS (25 Points)

Using the training data set, build at least three different multiple linear regression models, using different variables (or the same variables with different transformations). Since we have not yet covered automated variable selection methods, you should select the variables manually (unless you previously learned Forward or Stepwise selection, etc.). Since you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done.
Discuss the coefficients in the models, do they make sense? For example, if a team hits a lot of Home Runs, it would be reasonably expected that such a team would win more games. However, if the coefficient is negative (suggesting that the team would lose more games), then that needs to be discussed. Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.

## 4. SELECT MODELS (25 Points)
Decide on the criteria for selecting the best multiple linear regression model. Will you select a model with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your model.
For the multiple linear regression model, will you use a metric such as Adjusted R2, RMSE, etc.? Be sure to explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other relevant model output. Using the training data set, evaluate the multiple linear regression model based on 

a. mean squared error
b. R2, 
c. F-statistic, 
d. residual plots. 

Make predictions using the training_transformed data set.

```{r}
models <- list(model0,model1,model2,model3,model4,model5)

model_metrics <- lapply(models,function (m){ 
  s <- summary(m)
  res <- data.frame(r2=s$r.squared,
          rse=s$sigma,
          me=sqrt(mean(s$residuals^2)),
          fstatistic=head(c(s$fstatistic[1],1),1),
          fstatistic_df1=head(c(s$fstatistic[2],1),1),
          fstatistic_df2=head(c(s$fstatistic[3],nrow(valid_data)),1)
          )
  res
  })

combined_results <- do.call(rbind,model_metrics)
rownames(combined_results) <- NULL
combined_results <- data.frame(
  model = c("model0","model1","model2","model3","model4","model5"),
  description = c("Mean-based model","Model with Straight-Up Variables, Zero Intercept","Model with Y Power Transformation Using Boxcox","Model with X&Y  Power Transformation Using Boxcox", "Model with Y & Automatic Feature Set 1 w/Power Transformation Using Boxcox", "Model with Straight-Up Variables"),
  combined_results)

y_powers<- c(model0_y_power,model1_y_power,model2_y_power,model3_y_power,model4_y_power,model5_y_power)
combined_results$me <- combined_results$me ^ (1/y_powers)
kable(combined_results)


```



# Predictions

```{r}
# make up for missing values in the evaluation dataset by imputing wiht the training medians

# make up for missing TEAM_BATTING_SO
evaluation[is.na(evaluation$TEAM_BATTING_SO),]$TEAM_BATTING_SO <- median(training$TEAM_BATTING_SO, na.rm = TRUE)

# make up for missing TEAM_BASERUN_SB
evaluation[is.na(evaluation$TEAM_BASERUN_SB),]$TEAM_BASERUN_SB <- median(training$TEAM_BASERUN_SB, na.rm = TRUE)

# make up for missing TEAM_PITCHING_SO
evaluation[is.na(evaluation$TEAM_PITCHING_SO),]$TEAM_PITCHING_SO <- median(training$TEAM_PITCHING_SO, na.rm = TRUE)

# make up for missing TEAM_FIELDING_DP
evaluation[is.na(evaluation$TEAM_FIELDING_DP),]$TEAM_FIELDING_DP <- median(training$TEAM_FIELDING_DP, na.rm = TRUE)


# apply validation rules

evaluation$INVALID <- FALSE
evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_2B < 110 | evaluation$TEAM_BATTING_2B>376
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_3B < 11 | evaluation$TEAM_BATTING_3B>153
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_HR < 3 | evaluation$TEAM_BATTING_HR>264
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_H < 935 | evaluation$TEAM_BATTING_H>2131
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_SO < 308 | evaluation$TEAM_BATTING_SO>1535
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_PITCHING_SO < 308 | evaluation$TEAM_PITCHING_SO>1535
length(evaluation$INVALID[evaluation$INVALID])


evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_BATTING_BB < 282 | evaluation$TEAM_BATTING_BB>835
length(evaluation$INVALID[evaluation$INVALID])

evaluation$INVALID <- evaluation$INVALID | evaluation$TEAM_PITCHING_BB < 282 | evaluation$TEAM_PITCHING_BB>835
length(evaluation$INVALID[evaluation$INVALID])



model1_predictions <- predict(model1,evaluation)^(1/model1_y_power)
model1_predictions[evaluation$INVALID] <- NA

model2_predictions <- predict(model2,evaluation)^(1/model2_y_power)
model2_predictions[evaluation$INVALID] <- NA


kable(data.frame(model1_predictions = model1_predictions))


```